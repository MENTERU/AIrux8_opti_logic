# -*- coding: utf-8 -*-
"""
ã‚¨ã‚¢ã‚³ãƒ³æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ï¼ˆSTEP1ã€œSTEP4ä¸€è²«ç‰ˆ / å†è€ƒãƒªãƒ•ã‚¡ã‚¯ã‚¿ï¼‰
============================================================
è¦ç‚¹ï¼ˆã”è¦æœ›ã‚’åæ˜ ï¼‰
- IFï¼ˆã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰ã¨å‰å‡¦ç†ã€å¤©æ°—äºˆå ±å–å¾—ã€ãƒã‚¹ã‚¿æƒ…å ±ã®æ´»ç”¨ã‚’æœ€å„ªå…ˆã§å°Šé‡
- 1æ™‚é–“ç²’åº¦ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã€äºˆæ¸¬ç²’åº¦ã¯å¯å¤‰
- ãƒã‚¹ã‚¿JSONã‹ã‚‰åˆ¶å¾¡ã‚¨ãƒªã‚¢ï¼ˆzonesï¼‰ã€å®¤å¤–æ©Ÿ/å®¤å†…æ©Ÿã€è² è·ç‡(load_share)ã€ç›®æ¨™æ¸©åº¦ã‚„ç¯„å›²ã‚’å–å¾—
- å®Ÿç¸¾ï¼ˆç©ºèª¿ãƒ»é›»åŠ›ãƒ»å¤©å€™ï¼‰ã‚’æ•´å‚™ã—ã¦ã€åˆ¶å¾¡ã‚¨ãƒªã‚¢å˜ä½ã¸é›†ç´„
  - ç©ºèª¿: è¨­å®šæ¡ä»¶ã¯æœ€é »å€¤ã€å®¤å†…æ¸©åº¦ã¯å¹³å‡
  - é›»åŠ›: å®¤å¤–æ©Ÿã®æ¶ˆè²»é›»åŠ›Ã—è² è·ç‡ã®åˆè¨ˆ
  - å¤©å€™: ã‚¨ãƒªã‚¢é–“ã§å…±é€š
- äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«: åˆ¶å¾¡ã‚¨ãƒªã‚¢åˆ¥ã«ç’°å¢ƒï¼ˆå®¤æ¸©/æ¹¿åº¦ï¼‰ã¨é›»åŠ›ã‚’å­¦ç¿’
- æœ€é©åŒ–: åˆ¶å¾¡åŒºåˆ†æ¯ã€ãƒ‘ã‚¿ãƒ¼ãƒ³æ¢ç´¢â†’ç’°å¢ƒã¯å¹³å‡ã€é›»åŠ›ã¯åˆè¨ˆï¼ˆé›»åŠ›ã¯å®¤å†…æ©Ÿæ•°ã§è£œæ­£ï¼‰
- å‡ºåŠ›: åˆ¶å¾¡åŒºåˆ†åˆ¥ & å®¤å†…æ©Ÿåˆ¥ï¼ˆåˆ¶å¾¡åŒºåˆ†ã®é‹è»¢æ¡ä»¶ã‚’å®¤å†…æ©Ÿã«å±•é–‹ï¼‰

ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰æï¼ˆconfig.utils.get_data_path ã‚’ä½¿ç”¨ï¼‰
- raw_data_path/<store> ã« ac-control-*.csv, ac-power-meter-*.csv
- processed_data_path/<store> ã«å‰å‡¦ç†æ¸ˆã¿CSVã‚’å‡ºåŠ›
- models_path/<store> ã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜
- master/MASTER_<store>.json ã«ãƒã‚¹ã‚¿
- planning/<store> ã«åˆ¶å¾¡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«CSV
"""

from __future__ import annotations

import os
import time
import warnings
from dataclasses import dataclass
from typing import Optional, Tuple

import numpy as np
import pandas as pd

from optimization.optimizer import Optimizer
from optimization.parallel_optimizer import ParallelOptimizer
from optimization.period_optimizer import PeriodOptimizer
from planning.planner import Planner
from processing.aggregator import AreaAggregator
from processing.preprocessor import DataPreprocessor
from processing.utilities.master_loader import MasterLoader
from processing.utilities.weatherapi_client import VisualCrossingWeatherAPIDataFetcher
from training.model_builder import ModelBuilder

warnings.filterwarnings("ignore")


# =============================
# çµ±åˆãƒ©ãƒ³ãƒŠãƒ¼
# =============================
class AirconOptimizer:
    def __init__(self, store_name: str, enable_preprocessing: bool = True):
        self.store_name = store_name
        self.enable_preprocessing = enable_preprocessing
        self.master = MasterLoader(store_name).load()
        from config.utils import get_data_path

        self.proc_dir = os.path.join(get_data_path("processed_data_path"), store_name)
        self.plan_dir = os.path.join(get_data_path("output_data_path"), store_name)
        os.makedirs(self.plan_dir, exist_ok=True)

    def _load_processed(self) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
        ac_p = os.path.join(
            self.proc_dir, f"ac_control_processed_{self.store_name}.csv"
        )
        pm_p = os.path.join(
            self.proc_dir, f"power_meter_processed_{self.store_name}.csv"
        )
        ac = pd.read_csv(ac_p) if os.path.exists(ac_p) else None
        pm = pd.read_csv(pm_p) if os.path.exists(pm_p) else None
        return ac, pm

    def run(
        self,
        weather_api_key: Optional[str] = None,
        coordinates: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        freq: str = "1H",
        preference: str = "balanced",
        temperature_std_multiplier: float = 5.0,
        power_std_multiplier: float = 5.0,
    ):
        if self.master is None:
            print("[Run] ãƒã‚¹ã‚¿æœªèª­è¾¼")
            return None

        # å‡¦ç†æ™‚é–“è¨ˆæ¸¬é–‹å§‹
        total_start_time = time.perf_counter()
        processing_times = {}

        # åº§æ¨™æƒ…å ±ã‚’ãƒã‚¹ã‚¿ã‹ã‚‰å–å¾—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚‚è¨­å®šï¼‰
        if coordinates is None:
            coordinates = self.master.get("store_info", {}).get(
                "coordinates", "35.681236%2C139.767125"
            )
            print(f"[Run] Using coordinates from master: {coordinates}")
        else:
            print(f"[Run] Using provided coordinates: {coordinates}")

        # STEP1: å‰å‡¦ç†
        if self.enable_preprocessing:
            preprocessing_start_time = time.perf_counter()
            print("[Run] Starting preprocessing...")
            print(f"[Run] Temperature std multiplier: {temperature_std_multiplier}")
            print(f"[Run] Power std multiplier: {power_std_multiplier}")
            preprocessor = DataPreprocessor(self.store_name)
            print("[Run] DataPreprocessor created, loading raw data...")
            ac_raw_data, pm_raw_data = preprocessor.load_raw()
            print("[Run] Raw data loaded, preprocessing AC data...")
            ac_processed_data = preprocessor.preprocess_ac(
                ac_raw_data, temperature_std_multiplier
            )
            print("[Run] AC data preprocessed, preprocessing PM data...")
            pm_processed_data = preprocessor.preprocess_pm(
                pm_raw_data, power_std_multiplier
            )
            print("[Run] PM data preprocessed, saving...")
            preprocessor.save(ac_processed_data, pm_processed_data)
            preprocessing_end_time = time.perf_counter()
            processing_times["å‰å‡¦ç†"] = (
                preprocessing_end_time - preprocessing_start_time
            )
            print(
                f"[Run] Preprocessing completed - å‡¦ç†æ™‚é–“: {processing_times['å‰å‡¦ç†']:.2f}ç§’"
            )
        else:
            print("[Run] Loading processed data...")
            ac_processed_data, pm_processed_data = self._load_processed()
            print("[Run] Processed data loaded")
        # å¤©å€™ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆå®Ÿç¸¾æœŸé–“ï¼‹æœ€é©åŒ–æœŸé–“ã‚’ã‚«ãƒãƒ¼ï¼‰
        weather_start_time = time.perf_counter()

        # å®Ÿç¸¾æœŸé–“ã®æ¨å®šï¼ˆå‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
        actual_start_dt = None
        actual_end_dt = None
        try:
            if ac_processed_data is not None and not ac_processed_data.empty:
                ac_dt = pd.to_datetime(ac_processed_data.get("datetime"))
                actual_start_dt = ac_dt.min() if actual_start_dt is None else min(actual_start_dt, ac_dt.min())
                actual_end_dt = ac_dt.max() if actual_end_dt is None else max(actual_end_dt, ac_dt.max())
            if pm_processed_data is not None and not pm_processed_data.empty:
                pm_dt = pd.to_datetime(pm_processed_data.get("datetime"))
                actual_start_dt = pm_dt.min() if actual_start_dt is None else min(actual_start_dt, pm_dt.min())
                actual_end_dt = pm_dt.max() if actual_end_dt is None else max(actual_end_dt, pm_dt.max())
        except Exception:
            # ç„¡è¦–ï¼ˆå®Ÿç¸¾æœŸé–“ãŒå–ã‚Œãªã„å ´åˆã¯æœ€é©åŒ–æœŸé–“ã®ã¿ï¼‰
            pass

        # æœ€é©åŒ–æœŸé–“ã®æ—¢å®š
        if start_date is None or end_date is None:
            today = pd.Timestamp.today().normalize()
            start_date = today.strftime("%Y-%m-%d")
            end_date = (today + pd.Timedelta(days=3)).strftime("%Y-%m-%d")

        # å®Ÿç¸¾æœŸé–“ã¨æœ€é©åŒ–æœŸé–“ã‚’çµ±åˆã—ãŸå–å¾—ãƒ¬ãƒ³ã‚¸
        combined_start_dt = pd.to_datetime(start_date)
        combined_end_dt = pd.to_datetime(end_date)
        if actual_start_dt is not None:
            combined_start_dt = min(combined_start_dt, actual_start_dt.normalize())
        if actual_end_dt is not None:
            combined_end_dt = max(combined_end_dt, actual_end_dt.normalize())
        combined_start_date = combined_start_dt.strftime("%Y-%m-%d")
        combined_end_date = combined_end_dt.strftime("%Y-%m-%d")

        print(f"[Run] Weather API Key provided: {weather_api_key is not None}")
        if weather_api_key:
            print(f"[Run] Weather API Key: {weather_api_key[:10]}...")
        else:
            print("[Run] No Weather API Key provided")

        print(f"[Run] Date range (optimization): {start_date} to {end_date}")
        print(
            f"[Run] Date range (weather fetch combined): {combined_start_date} to {combined_end_date}"
        )
        print(f"[Run] Coordinates: {coordinates}")

        weather_df = None
        if weather_api_key:
            print("[Run] Attempting to fetch weather data from API...")
            try:
                # æœˆæ¬¡ãƒãƒ£ãƒ³ã‚¯ã§åˆ†å‰²å–å¾—ï¼ˆAPIã‚³ã‚¹ãƒˆå›é¿ï¼‰
                cur = combined_start_dt
                chunks = []
                while cur <= combined_end_dt:
                    chunk_start = cur
                    # æœˆæœ«ã¾ã§ or combined_end_dt ã¾ã§
                    next_month = (chunk_start.replace(day=1) + pd.offsets.MonthEnd(1)).to_pydatetime()
                    chunk_end = pd.Timestamp(min(next_month, combined_end_dt))
                    s = chunk_start.strftime("%Y-%m-%d")
                    e = chunk_end.strftime("%Y-%m-%d")
                    print(f"[Weather] Fetching chunk: {s} -> {e}")
                    try:
                        chunk_df = VisualCrossingWeatherAPIDataFetcher(
                            coordinates=coordinates,
                            start_date=s,
                            end_date=e,
                            unit="metric",
                            api_key=weather_api_key,
                        ).fetch()
                        if chunk_df is not None and not chunk_df.empty:
                            chunks.append(chunk_df)
                    except Exception as ce:
                        print(f"[Weather] Chunk fetch failed: {ce}")
                    # æ¬¡ã®é–‹å§‹ã¯ç¿Œæœˆ1æ—¥
                    cur = (chunk_end + pd.Timedelta(days=1)).normalize()
                if chunks:
                    weather_df = pd.concat(chunks, axis=0, ignore_index=True)
                    # é‡è¤‡é™¤å»
                    if "datetime" in weather_df.columns:
                        weather_df["datetime"] = pd.to_datetime(weather_df["datetime"]).dt.floor("H")
                        weather_df = weather_df.drop_duplicates(subset=["datetime"]).sort_values("datetime")
                print(f"[Run] Weather API result: {weather_df is not None}")
                if weather_df is not None:
                    print(f"[Run] Weather data shape: {weather_df.shape}")
                    print(f"[Run] Weather data columns: {list(weather_df.columns)}")
            except Exception as e:
                print(f"[Run] Weather API exception: {e}")
                weather_df = None

        weather_end_time = time.perf_counter()
        processing_times["å¤©å€™ãƒ‡ãƒ¼ã‚¿å–å¾—"] = weather_end_time - weather_start_time
        print(
            f"[Run] Weather data processing completed - å‡¦ç†æ™‚é–“: {processing_times['å¤©å€™ãƒ‡ãƒ¼ã‚¿å–å¾—']:.2f}ç§’"
        )

        # åˆ¶å¾¡ã‚¨ãƒªã‚¢é›†ç´„
        aggregation_start_time = time.perf_counter()
        print("[Run] Starting area aggregation...")
        aggregator = AreaAggregator(self.master)
        area_df = aggregator.build(
            ac_processed_data, pm_processed_data, weather_df, freq=freq
        )
        print(
            f"[Run] Area aggregation completed. Shape: {area_df.shape if area_df is not None else 'None'}"
        )

        if area_df is not None and not area_df.empty:
            print(f"[Run] Area data columns: {list(area_df.columns)}")
            print(
                f"[Run] Zones found: {area_df['zone'].unique() if 'zone' in area_df.columns else 'No zone column'}"
            )
            print(
                f"[Run] Adjusted power data: {area_df['adjusted_power'].notna().sum() if 'adjusted_power' in area_df.columns else 'No adjusted_power column'}"
            )

        area_out = os.path.join(
            self.proc_dir, f"features_processed_{self.store_name}.csv"
        )
        os.makedirs(self.proc_dir, exist_ok=True)
        area_df.to_csv(area_out, index=False, encoding="utf-8-sig")
        print(f"[Run] Area data saved to: {area_out}")
        
        # å¤©æ°—äºˆå ±ãƒ‡ãƒ¼ã‚¿ã®å‡ºåŠ›ï¼ˆæœ€é©åŒ–æœŸé–“ã®ã¿ï¼‰
        if weather_df is not None:
            forecast_df = weather_df[
                (weather_df["datetime"] >= pd.to_datetime(start_date))
                & (weather_df["datetime"] <= pd.to_datetime(end_date))
            ].copy()
            forecast_path = os.path.join(
                get_data_path("output_data_path"), store_name, "weather_forecast.csv"
            )
            os.makedirs(os.path.dirname(forecast_path), exist_ok=True)
            forecast_df.to_csv(forecast_path, index=False, encoding="utf-8-sig")
            print(f"[Run] Weather forecast saved to: {forecast_path}")

        aggregation_end_time = time.perf_counter()
        processing_times["ã‚¨ãƒªã‚¢é›†ç´„"] = aggregation_end_time - aggregation_start_time
        print(
            f"[Run] Area aggregation completed - å‡¦ç†æ™‚é–“: {processing_times['ã‚¨ãƒªã‚¢é›†ç´„']:.2f}ç§’"
        )

        # STEP2: äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
        model_training_start_time = time.perf_counter()
        print("[Run] Starting model training...")
        builder = ModelBuilder(self.store_name)
        models = builder.train_by_zone(area_df, self.master)
        model_training_end_time = time.perf_counter()
        processing_times["ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"] = (
            model_training_end_time - model_training_start_time
        )
        print(
            f"[Run] Model training completed. Models created: {len(models)} - å‡¦ç†æ™‚é–“: {processing_times['ãƒ¢ãƒ‡ãƒ«å­¦ç¿’']:.2f}ç§’"
        )
        if not models:
            print("[Run] ãƒ¢ãƒ‡ãƒ«ä½œæˆä¸å¯ï¼ˆãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼‰")
            return None

        # STEP3: æœ€é©åŒ–ï¼ˆä¸¦åˆ—å‡¦ç†ç‰ˆï¼‰
        optimization_start_time = time.perf_counter()
        date_range = pd.date_range(
            start=pd.to_datetime(start_date), end=pd.to_datetime(end_date), freq=freq
        )
        date_range = date_range[(date_range.hour >= 0) & (date_range.hour <= 23)]

        # æœŸé–“æœ€é©åŒ–ç‰ˆã‚’ä½¿ç”¨ï¼ˆé›»åŠ›åˆè¨ˆã€å®¤æ¸©å¹³å‡ã§è©•ä¾¡ï¼‰
        opt = PeriodOptimizer(self.master, models, max_workers=6)  # 6ã‚¾ãƒ¼ãƒ³åˆ†
        schedule = opt.optimize_period(date_range, weather_df, preference=preference)
        optimization_end_time = time.perf_counter()
        processing_times["æœ€é©åŒ–"] = optimization_end_time - optimization_start_time
        print(
            f"[Run] Optimization completed - å‡¦ç†æ™‚é–“: {processing_times['æœ€é©åŒ–']:.2f}ç§’"
        )

        # STEP4: å‡ºåŠ›
        output_start_time = time.perf_counter()
        Planner(self.store_name, self.master).export(schedule, self.plan_dir)
        output_end_time = time.perf_counter()
        processing_times["è¨ˆç”»å‡ºåŠ›"] = output_end_time - output_start_time
        print(
            f"[Run] Planning output completed - å‡¦ç†æ™‚é–“: {processing_times['è¨ˆç”»å‡ºåŠ›']:.2f}ç§’"
        )

        # ç·å‡¦ç†æ™‚é–“ã®è¡¨ç¤º
        total_end_time = time.perf_counter()
        processing_times["ç·å‡¦ç†æ™‚é–“"] = total_end_time - total_start_time

        print(f"\n{'='*60}")
        print("ğŸ“Š å‡¦ç†æ™‚é–“ã‚µãƒãƒªãƒ¼")
        print(f"{'='*60}")
        for process_name, duration in processing_times.items():
            if process_name != "ç·å‡¦ç†æ™‚é–“":
                percentage = (duration / processing_times["ç·å‡¦ç†æ™‚é–“"]) * 100
                print(f"{process_name:12}: {duration:6.2f}ç§’ ({percentage:5.1f}%)")
        print(f"{'='*60}")
        print(f"{'ç·å‡¦ç†æ™‚é–“':12}: {processing_times['ç·å‡¦ç†æ™‚é–“']:6.2f}ç§’ (100.0%)")
        print(f"{'='*60}")

        return schedule


if __name__ == "__main__":
    # ä¾‹:
    # AirconOptimizer("STORE_A").run(weather_api_key="YOUR_API_KEY")
    pass
